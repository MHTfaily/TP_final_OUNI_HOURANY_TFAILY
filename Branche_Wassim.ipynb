{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9eaaaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score, adjusted_rand_score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score, adjusted_rand_score\n",
    "\n",
    "'''\n",
    "Variables: \n",
    "---------\n",
    "\n",
    "corpus : list of documents\n",
    "embeddings : documents embeddings of size NxM (N : number of documents, M : embedding dimension) \n",
    "red_emd : reduced embeddings matrix using dimentionality reduction\n",
    "k : number of clusters\n",
    "labels : documents labels\n",
    "pred : list of clustering predicted clusters \n",
    "\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84b62ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données NG20\n",
    "ng20 = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "corpus = ng20.data[:2000]  # Utiliser seulement 2000 documents pour des raisons de démonstration\n",
    "labels = ng20.target[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e525968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "671c8527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[''\n",
      " \"\\t daved@world.std.com (Dave T Dorfman) writes...\\n]I was enjoying lunch this saturday at foodies in Milford NH with an assortment\\n]of other nedod folks when Dean Cookson ( yes he has not left the \\n]country, yet) mentioned that the wiring diagram of the VFR750 \\n]shows that  the light switch is a three position switch. \\n\\n]high beam\\n]low beam\\n]Both beams\\n\\n]Well the actual ergonomics of the switch make it appear to be a\\n]2 position switch, but sure enough as Deam expected , when\\n]you balance the toggle switch in the center position both the high\\n]and low beams go on.\\n\\n]This provides a very nice light coverage of the road.\\n\\n]This is true for the St11 and the VFR750 and I would expect for any \\n]other late model Honda with the standard two position light switch.\\n\\n]Thanks to Dean for reading the schematics, try it you'll like it.\\n\\n\\tBe a bit careful doing this; I used to balance the switch on my GS550B\\navec Cibie' H4 insert so that both beams were on.  I eventually fried the\\nmain ignition switch, as it wasn't designed to pass that sort of current.\"\n",
      " '\\tI heard that there is a VESA driver for the XGA-2 card available on \\ncompuserve. I just got this card, and I am wondering if this driver is \\navailable on a FTP site anywhere. My news service has beeen erratic lately so\\nplease E-Mail me at:\\n\\t\\t\\t\\twalsh@stolaf.edu\\n\\tThanks in advance. \\n'\n",
      " ...\n",
      " '}>}(a) out of context;\\n}>Must have missed when you said this about these other \"promises of god\" that we keep\\n}>getting subjected to.  Could you please explain why I am wrong and they are OK?\\n}>Or an acknowledgement of public hypocrisy. Both or neither.\\n}\\n}So, according to you, Jim, the only way to criticize one person for\\n}taking a quote out of context, without being a hypocrite, is to post a\\n}response to *every* person on t.r.m who takes a quote out of context?\\n\\nDid I either ask or assert that?  Or is this your misaimed telepathy at work again?\\n\\n}>BTW to David Josli:  I\\'m still waiting for either your public\\n}>acknowledgement of your\\n}>telepathy and precognition (are you a witch?) or an appology and retraction.\\n}\\n}Can you wait without whining? To pass the time, maybe you should go\\n}back and read the portions of my article that you so conveniently\\n}deleted in your reply.  You\\'ll find most of your answers there.  \\n\\nNope:  In particular:\\nExample of telepathy?\\n\\nWhat threat.  Produce it.\\n\\nMore telepathy?  Or maybe just empathic telepathy, capable of determining emotional states.\\n\\nMore telepathy.  How do you know \"trying\"?!?!?\\n\\nPrecognition?  Substantiate.  '\n",
      " '}Dillon has published a letter in the Blue Press telling people\\n}\"How to Bankrupt HCI\" by requesting information from them.\\n}\\n}Last time this idea went around in rec.guns, a couple of people\\n}said that HCI counts all information requestors as \"members\".\\n}\\n}Can anyone confirm or deny this?\\n}\\n}If true, what\\'s the impact of HCI getting a few thousand new\\n}members?\\n\\nLast I heard, HCI had something like 250K members to the NRA\\'s 3 million.\\nIf true, and they want to play duelling mandates, well ...'\n",
      " '}start her up and rev to about 3000 rpm....I FAIL cuz I register 120 DB,\\n}and the max allowed is 110! If I fail with these pipes, there are gonna\\n\\nNext time make the numbers more believable -- this is poor flamebait.\\n120 DB is getting close to the sound of a jumbo jet engine at takeoff\\nrevs from some small number of yards away. It is certainly right\\naround the pain threshold for humans. No way in hell the state permits\\n110 DB if they have any standard at all.\\n']\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e77a0f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_red(mat, p):\n",
    "    '''\n",
    "    Perform dimensionality reduction\n",
    "\n",
    "    Input:\n",
    "    -----\n",
    "        mat : NxM list \n",
    "        p : number of dimensions to keep \n",
    "    Output:\n",
    "    ------\n",
    "        red_mat : NxP list such that p<<m\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    pca = PCA(n_components=p)\n",
    "    \n",
    "    # Appliquer l'ACP et réduire la dimensionnalité\n",
    "    red_mat = pca.fit_transform(mat)\n",
    "    \n",
    "    \n",
    "    \n",
    "   # red_mat = mat[:,:p]\n",
    "    \n",
    "    return red_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f2ae938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clust(mat, k):\n",
    "    '''\n",
    "    Perform clustering\n",
    "\n",
    "    Input:\n",
    "    -----\n",
    "        mat : input list \n",
    "        k : number of cluster\n",
    "    Output:\n",
    "    ------\n",
    "        pred : list of predicted labels\n",
    "    '''\n",
    "    # Initialiser l'objet KMeans\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    \n",
    "    # Appliquer k-means sur la matrice d'entrée\n",
    "    pred = kmeans.fit_predict(mat)\n",
    "    \n",
    "   # pred = np.random.randint(k, size=len(corpus))\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7ca9d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI: 0.40 \n",
      "ARI: 0.24\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "ng20 = fetch_20newsgroups(subset='test')\n",
    "corpus = ng20.data[:2000]\n",
    "labels = ng20.target[:2000]\n",
    "k = len(set(labels))\n",
    "\n",
    "# embedding\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "embeddings = model.encode(corpus)\n",
    "\n",
    "# perform dimentionality reduction\n",
    "red_emb = dim_red(embeddings, 20)\n",
    "\n",
    "# perform clustering\n",
    "pred = clust(red_emb, k)\n",
    "\n",
    "# evaluate clustering results\n",
    "nmi_score = normalized_mutual_info_score(pred,labels)\n",
    "ari_score = adjusted_rand_score(pred,labels)\n",
    "\n",
    "print(f'NMI: {nmi_score:.2f} \\nARI: {ari_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22884999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
